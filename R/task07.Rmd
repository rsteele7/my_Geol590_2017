---
title: "R Notebook"
output: md_document
---
#NYC Flights Code
```{r}
#---------------------------------#
######task 7 nycflights code#######
#---------------------------------#
#loading appropriate libraries
library(nycflights13)
library(tidyverse)



#-------------Prepare weather data for placement in tables, graph---------------#
#-------------------------------------------------------------------------------#
#plot wind speed to visualise outliers
nycflights13::weather %>%
  ggplot(aes(hour, wind_speed)) +
    geom_point()


#remove outlier > 1,000 units of wind speed and values in wind_dir = NA
#summarise with median wind speed for each wind direction at each airport
airport_wind <- nycflights13::weather %>%
  filter(wind_speed<1000, !is.na(wind_dir)) %>%
  group_by(wind_dir,origin) %>%
  summarise(med_wind_spd = median(wind_speed)) %>%
  .[order(.$origin), ]


#Determine directions with highest median speeds at each airport
print(top_n(group_by(airport_wind, origin), 1, med_wind_spd))



#---------------------Put weather data in tables and graphs-----------------------#
#---------------------------------------------------------------------------------#
#create separate tables of median wind speed/direction for every airport
airport_wind_tbls <- airport_wind %>%
  group_by(origin) %>%
  do(airport_wind=data.frame(.)) %>%
  select(airport_wind) %>%
  lapply(function(x) {(x)})
ewr_wind <- airport_wind_tbls$airport_wind[[1]]
jfk_wind <- airport_wind_tbls$airport_wind[[2]]
lga_wind <- airport_wind_tbls$airport_wind[[3]]


#make graphs of median wind speed/direction for every airport
airport_wind %>%
  ggplot(aes(x=wind_dir, y=med_wind_spd)) +
    geom_point() +
    facet_wrap(~origin) +
    xlab("Wind Direction") +
    ylab("Wind Speed")



#---------------------------------------JFK distance data---------------------------------------------------#
#-----------------------------------------------------------------------------------------------------------#
#Make table with airline name and median distance flown from JFK; arrange in order of decreasing mean flight distance
jfk_flight_distance <- nycflights13::flights %>%
  left_join(airlines) %>%
  filter(origin == "JFK") %>%
  group_by(name) %>%
  summarise(med_dist = median(distance), mean_dist = mean(distance)) %>%
  .[order(.$mean_dist), ] %>%
  print()



#--------------------------------------EWR flight number data---------------------------------------------#
#---------------------------------------------------------------------------------------------------------#
#Make wide data frame displaying number of flights leaving Newark airport each month from each airline
leave_ewr <- nycflights13::flights %>%
  filter(origin == "EWR") %>%
  group_by(carrier, month) %>%
  summarise(flight_num = n()) %>%
  spread(carrier, flight_num) %>%
  print()

```
#Babynames Code

```{r}
#--------------------------------#
######task 7 babynames code#######
#--------------------------------#
library(babynames)


#-Collecting and plotting most common baby names in 2014 across the years-#
#-------------------------------------------------------------------------#
#collect 10 most common male and female baby names in 2014 
common_2014 <- babynames::babynames %>%
  filter(year==2014) %>%
  group_by(sex) %>%
  top_n(10, prop)


#select frequencies throughout the years of the given baby names, plot
keys <- c("name", "sex")
babynames::babynames %>%
  merge(., common_2014[keys], by=keys) %>% #selects all babies of correct sex and name
  ggplot(aes(x=year, y=prop)) +
    geom_col() +
    facet_wrap(~name)



#-------------------common girl data-------------------------#
#------------------------------------------------------------#
#26th - 29th most common girls in 1896, 1942, 2016
common_girls <- babynames::babynames %>%
  filter(year==1896 | year==1942 | year==2016, sex=="F") %>%
  group_by(year) %>%
  top_n(29, prop)  %>%
  top_n(-4, prop) %>%
  print()
```

#Data Wrangling Code

Complete the following tasks using the package nasaweather and data wrangling methods.

In the glacier dataset:

* determine the id's and names of the largest (by area) glaciers for each country
* determine the latitude and longitude of the single largest glacier

In the storm dataset:
* determine the average wind and its variance for each type of storm
* determine the number and names of hurricanes in 1999



```{r}
#----------------------------------#
#####task 7 data wrangling code#####
#----------------------------------#

#load appropriate libraries
library(nasaweather)



#----------------------glacier data---------------------------#
#-------------------------------------------------------------#


#determining largest glaciers in each country
country_largest_glaciers <- nasaweather::glaciers %>%
  group_by(country) %>%
  top_n(1, area) %>%
  select(id, name, area, country) %>%
  print()


#latitude and longitude of largest glacier in the dataset
largest_glacier <- nasaweather::glaciers %>%
  top_n(1, area) %>%
  select(name, lat, long, country) %>%
  print()


#-----------------------------storm data--------------------------------#
#-----------------------------------------------------------------------#


#determining average wind and variance for each type of storm
storm_wind_spd <- nasaweather::storms %>%
  group_by(type) %>%
  summarise(av_wind = mean(wind), var_wind = var(wind)) %>%
  print()


#determining number of hurricanes in 1999
hurricane_1999 <- nasaweather::storms %>%
  filter(type == "Hurricane", year == 1999) %>%
  select(name) %>%
  group_by(name) %>%
  summarise() %>%
  print()
```

